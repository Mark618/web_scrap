{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import nltk\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mark/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_df= pd.read_csv(\"book_sum.csv\")\n",
    "br_df =br_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>freebase_id</th>\n",
       "      <th>book_title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>book_genre</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620</td>\n",
       "      <td>/m/0hhy</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>['Roman à clef', 'Satire', \"Children's literat...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843</td>\n",
       "      <td>/m/0k36</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>['Science Fiction', 'Novella', 'Speculative fi...</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>/m/0ldx</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>['Existentialism', 'Fiction', 'Absurdist ficti...</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2152</td>\n",
       "      <td>/m/0x5g</td>\n",
       "      <td>All Quiet on the Western Front</td>\n",
       "      <td>Erich Maria Remarque</td>\n",
       "      <td>1929-01-29</td>\n",
       "      <td>['War novel', 'Roman à clef']</td>\n",
       "      <td>The book tells the story of Paul Bäumer, a Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2890</td>\n",
       "      <td>/m/011zx</td>\n",
       "      <td>A Wizard of Earthsea</td>\n",
       "      <td>Ursula K. Le Guin</td>\n",
       "      <td>1968</td>\n",
       "      <td>[\"Children's literature\", 'Fantasy', 'Speculat...</td>\n",
       "      <td>Ged is a young boy on Gont, one of the larger...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id freebase_id                      book_title                author  \\\n",
       "0      620     /m/0hhy                     Animal Farm         George Orwell   \n",
       "1      843     /m/0k36              A Clockwork Orange       Anthony Burgess   \n",
       "2      986     /m/0ldx                      The Plague          Albert Camus   \n",
       "3     2152     /m/0x5g  All Quiet on the Western Front  Erich Maria Remarque   \n",
       "4     2890    /m/011zx            A Wizard of Earthsea     Ursula K. Le Guin   \n",
       "\n",
       "     pub_date                                         book_genre  \\\n",
       "0  1945-08-17  ['Roman à clef', 'Satire', \"Children's literat...   \n",
       "1        1962  ['Science Fiction', 'Novella', 'Speculative fi...   \n",
       "2        1947  ['Existentialism', 'Fiction', 'Absurdist ficti...   \n",
       "3  1929-01-29                      ['War novel', 'Roman à clef']   \n",
       "4        1968  [\"Children's literature\", 'Fantasy', 'Speculat...   \n",
       "\n",
       "                                             summary  \n",
       "0   Old Major, the old boar on the Manor Farm, ca...  \n",
       "1   Alex, a teenager living in near-future Englan...  \n",
       "2   The text of The Plague is divided into five p...  \n",
       "3   The book tells the story of Paul Bäumer, a Ge...  \n",
       "4   Ged is a young boy on Gont, one of the larger...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.indexing._LocIndexer at 0x7f88a6fccb80>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br_df.loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mark/Documents/web_scrap/sim.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mark/Documents/web_scrap/sim.ipynb#ch0000005?line=0'>1</a>\u001b[0m tagged_data \u001b[39m=\u001b[39m [TaggedDocument(words\u001b[39m=\u001b[39mword_tokenize(_d\u001b[39m.\u001b[39mlower()), tags\u001b[39m=\u001b[39m[\u001b[39mstr\u001b[39m(i)]) \u001b[39mfor\u001b[39;00m i, _d \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(br_df[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m])]\n",
      "\u001b[1;32m/home/mark/Documents/web_scrap/sim.ipynb Cell 7'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mark/Documents/web_scrap/sim.ipynb#ch0000005?line=0'>1</a>\u001b[0m tagged_data \u001b[39m=\u001b[39m [TaggedDocument(words\u001b[39m=\u001b[39mword_tokenize(_d\u001b[39m.\u001b[39;49mlower()), tags\u001b[39m=\u001b[39m[\u001b[39mstr\u001b[39m(i)]) \u001b[39mfor\u001b[39;00m i, _d \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(br_df[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m])]\n",
      "File \u001b[0;32m~/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py:130\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=114'>115</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=115'>116</a>\u001b[0m \u001b[39mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=116'>117</a>\u001b[0m \u001b[39musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=126'>127</a>\u001b[0m \u001b[39m:type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=127'>128</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=128'>129</a>\u001b[0m sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m--> <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=129'>130</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=130'>131</a>\u001b[0m     token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39mtokenize(sent)\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=131'>132</a>\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py:131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=114'>115</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=115'>116</a>\u001b[0m \u001b[39mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=116'>117</a>\u001b[0m \u001b[39musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=126'>127</a>\u001b[0m \u001b[39m:type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=127'>128</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=128'>129</a>\u001b[0m sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=129'>130</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m--> <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=130'>131</a>\u001b[0m     token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39;49mtokenize(sent)\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=131'>132</a>\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/destructive.py:179\u001b[0m, in \u001b[0;36mNLTKWordTokenizer.tokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/destructive.py?line=175'>176</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m text \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/destructive.py?line=177'>178</a>\u001b[0m \u001b[39mfor\u001b[39;00m regexp, substitution \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mENDING_QUOTES:\n\u001b[0;32m--> <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/destructive.py?line=178'>179</a>\u001b[0m     text \u001b[39m=\u001b[39m regexp\u001b[39m.\u001b[39;49msub(substitution, text)\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/destructive.py?line=180'>181</a>\u001b[0m \u001b[39mfor\u001b[39;00m regexp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCONTRACTIONS2:\n\u001b[1;32m    <a href='file:///home/mark/Documents/web_scrap/.venv/lib/python3.8/site-packages/nltk/tokenize/destructive.py?line=181'>182</a>\u001b[0m     text \u001b[39m=\u001b[39m regexp\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\\\u001b[39m\u001b[39m1 \u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2 \u001b[39m\u001b[39m\"\u001b[39m, text)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(br_df['summary'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=30, min_count=2, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update model\n",
    "# model.build_vocab(data_part2, update=True)\n",
    "# model.train(data_part2, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/sim.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Doc2Vec.load('model/sim.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_doc = model.dv.most_similar('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('5891', 0.8199803829193115)\n"
     ]
    }
   ],
   "source": [
    "print(similar_doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.017878199"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dv.similarity(0,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9293, 7)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br_df.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8101e1b09e9e663bcba21d7557d2c251b68facdd702628e2fcb2cb7bd4c3e7e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
